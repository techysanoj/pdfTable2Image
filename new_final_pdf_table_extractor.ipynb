{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import os\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the class of the PDF Table extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFTableExtractor:\n",
    "    def __init__(self, pdf_path, output_dir=\"extracted_tables\", heading_margin=200):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.pages = None\n",
    "        self.heading_margin = heading_margin\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "    def convert_pdf_to_images(self):\n",
    "        \"\"\"Convert PDF pages to images.\"\"\"\n",
    "        try:\n",
    "            self.pages = convert_from_path(self.pdf_path, dpi=300)\n",
    "            return self.pages\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting PDF to images: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def detect_text_regions(self, gray_image):\n",
    "        \"\"\"Detect text regions that might indicate table headers.\"\"\"\n",
    "        try:\n",
    "            data = pytesseract.image_to_data(gray_image, output_type=pytesseract.Output.DICT)\n",
    "            potential_headers = []\n",
    "            \n",
    "            for i in range(len(data['text'])):\n",
    "                if int(data['conf'][i]) > 60:  # Filter for confident text detection\n",
    "                    text = data['text'][i].strip().lower()\n",
    "                    if len(text) > 3:  # Filter out very short text\n",
    "                        x = data['left'][i]\n",
    "                        y = data['top'][i]\n",
    "                        w = data['width'][i]\n",
    "                        h = data['height'][i]\n",
    "                        potential_headers.append((x, y, w, h, text))\n",
    "            \n",
    "            return potential_headers\n",
    "        except Exception as e:\n",
    "            print(f\"Error detecting text regions: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def is_likely_table(self, contour, image_shape, text_regions):\n",
    "        \"\"\"Enhanced table detection with improved filtering for headers/footers.\"\"\"\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        area = cv2.contourArea(contour)\n",
    "        rect_area = w * h\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        \n",
    "        # Basic shape metrics\n",
    "        circularity = 4 * np.pi * area / (perimeter * perimeter) if perimeter > 0 else 0\n",
    "        rectangularity = area / rect_area if rect_area > 0 else 0\n",
    "        aspect_ratio = w / h if h > 0 else 0\n",
    "        relative_size = area / (image_shape[0] * image_shape[1])\n",
    "\n",
    "        # Filter out regions that are likely headers or footers\n",
    "        # Headers and footers typically span the full width of the page\n",
    "        page_width = image_shape[1]\n",
    "        is_full_width = w > page_width * 0.9\n",
    "        \n",
    "        # Headers and footers are usually at the top or bottom 10% of the page\n",
    "        page_height = image_shape[0]\n",
    "        is_at_edge = y < page_height * 0.1 or (y + h) > page_height * 0.9\n",
    "        \n",
    "        # If region is both full-width and at page edge, likely a header/footer\n",
    "        if is_full_width and is_at_edge:\n",
    "            return False\n",
    "\n",
    "        # Check for table-like structure\n",
    "        has_headers = False\n",
    "        header_text_count = 0\n",
    "        for tx, ty, tw, th, text in text_regions:\n",
    "            if (x <= tx <= x + w and y <= ty <= y + h):\n",
    "                has_headers = True\n",
    "                header_text_count += 1\n",
    "\n",
    "        # Require multiple text regions for a valid table\n",
    "        if header_text_count < 2:\n",
    "            return False\n",
    "\n",
    "        # More lenient criteria for regions with headers\n",
    "        if has_headers:\n",
    "            return (\n",
    "                circularity < 0.9 and\n",
    "                rectangularity > 0.3 and\n",
    "                0.2 < aspect_ratio < 25.0 and\n",
    "                0.01 < relative_size < 0.8 and  # Adjusted size constraints\n",
    "                w > 50 and h > 50 and  # Minimum dimensions\n",
    "                w < page_width * 0.95  # Should not span entire page width\n",
    "            )\n",
    "        else:\n",
    "            # Stricter criteria for regions without headers\n",
    "            return (\n",
    "                circularity < 0.7 and\n",
    "                rectangularity > 0.6 and\n",
    "                0.5 < aspect_ratio < 15.0 and\n",
    "                0.02 < relative_size < 0.7 and\n",
    "                w > 100 and h > 50 and\n",
    "                w < page_width * 0.9\n",
    "            )\n",
    "\n",
    "    def detect_tables(self, page_image):\n",
    "        \"\"\"Enhanced table detection with improved filtering.\"\"\"\n",
    "        try:\n",
    "            img_array = np.array(page_image)\n",
    "            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "            \n",
    "            # Detect text regions first\n",
    "            text_regions = self.detect_text_regions(gray)\n",
    "            \n",
    "            # Multiple threshold approaches\n",
    "            thresh_adaptive = cv2.adaptiveThreshold(\n",
    "                gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 3\n",
    "            )\n",
    "            \n",
    "            _, thresh_binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "            thresh = cv2.bitwise_or(thresh_adaptive, thresh_binary)\n",
    "            \n",
    "            # Morphological operations\n",
    "            kernel_small = np.ones((3, 3), np.uint8)\n",
    "            kernel_large = np.ones((5, 5), np.uint8)\n",
    "            \n",
    "            thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel_small)\n",
    "            thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel_small)\n",
    "            thresh = cv2.dilate(thresh, kernel_large, iterations=1)\n",
    "\n",
    "            # Find contours\n",
    "            contours_ext, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contours_tree, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            all_contours = contours_ext + contours_tree\n",
    "            table_regions = set()\n",
    "            min_area = 5000  # Increased minimum area\n",
    "            \n",
    "            for contour in all_contours:\n",
    "                if cv2.contourArea(contour) > min_area and self.is_likely_table(contour, gray.shape, text_regions):\n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "                    \n",
    "                    # Check for table structure\n",
    "                    roi = thresh[y:y+h, x:x+w]\n",
    "                    h_kernel_size = max(w//8, 20)\n",
    "                    v_kernel_size = max(h//8, 20)\n",
    "                    \n",
    "                    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (h_kernel_size, 1))\n",
    "                    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, v_kernel_size))\n",
    "                    \n",
    "                    horizontal_lines = cv2.morphologyEx(roi, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "                    vertical_lines = cv2.morphologyEx(roi, cv2.MORPH_OPEN, vertical_kernel)\n",
    "                    \n",
    "                    # Require either lines or multiple text regions\n",
    "                    has_lines = (np.sum(horizontal_lines) > roi.size * 0.001 or \n",
    "                               np.sum(vertical_lines) > roi.size * 0.001)\n",
    "                    \n",
    "                    text_in_region = [t for t in text_regions if \n",
    "                                    x <= t[0] <= x + w and y <= t[1] <= y + h]\n",
    "                    \n",
    "                    if has_lines or len(text_in_region) >= 3:  # Require at least 3 text regions\n",
    "                        # Don't extend margin for headers if near page edge\n",
    "                        if y > gray.shape[0] * 0.1:  # Only if not at top of page\n",
    "                            y = max(0, y - self.heading_margin)\n",
    "                            h = h + self.heading_margin\n",
    "                        table_regions.add((x, y, w, h))\n",
    "\n",
    "            return sorted(list(table_regions), key=lambda x: x[1])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error detecting tables: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def extract_text_from_image(self, image):\n",
    "        \"\"\"Extract text from an image using OCR.\"\"\"\n",
    "        try:\n",
    "            text = pytesseract.image_to_string(image)\n",
    "            return text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from image: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    def is_region_overlapping(self, region, processed_regions):\n",
    "        \"\"\"Check if a region overlaps with any of the processed regions.\"\"\"\n",
    "        x1, y1, w1, h1 = region\n",
    "        for px, py, pw, ph in processed_regions:\n",
    "            if not (x1 + w1 < px or px + pw < x1 or y1 + h1 < py or py + ph < y1):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def extract_table_images(self):\n",
    "        \"\"\"Extract table images and save them in respective folders.\"\"\"\n",
    "        if not self.pages:\n",
    "            self.convert_pdf_to_images()\n",
    "        if not self.pages:\n",
    "            return\n",
    "\n",
    "        for page_num, page in enumerate(self.pages):\n",
    "            try:\n",
    "                \n",
    "                page_folder = os.path.join(self.output_dir, f\"page_{page_num + 1}\")\n",
    "                os.makedirs(page_folder, exist_ok=True)\n",
    "\n",
    "                table_regions = self.detect_tables(page)\n",
    "                processed_regions = []\n",
    "                table_counter = 1\n",
    "\n",
    "                i = 0\n",
    "                while i < len(table_regions):\n",
    "                    x, y, w, h = table_regions[i]\n",
    "                    \n",
    "                    if self.is_region_overlapping((x, y, w, h), processed_regions):\n",
    "                        i += 1\n",
    "                        continue\n",
    "\n",
    "                    current_table = page.crop((x, y, x + w, y + h))\n",
    "                    text = self.extract_text_from_image(current_table)\n",
    "                    \n",
    "                    if \"Last 5 Encounters\" in text:\n",
    "                        x_min, y_min = x, y\n",
    "                        x_max, y_max = x + w, y + h\n",
    "                        \n",
    "                        j = i + 1\n",
    "                        while j < len(table_regions):\n",
    "                            next_x, next_y, next_w, next_h = table_regions[j]\n",
    "                            if next_y > y and abs(next_x - x) < w * 0.5:\n",
    "                                x_min = min(x_min, next_x)\n",
    "                                x_max = max(x_max, next_x + next_w)\n",
    "                                y_max = max(y_max, next_y + next_h)\n",
    "                            j += 1\n",
    "\n",
    "                        combined_image = page.crop((x_min, y_min, x_max, y_max))\n",
    "                        combined_image.save(os.path.join(page_folder, \"last_5_encounters_combined.png\"))\n",
    "                        processed_regions.append((x_min, y_min, x_max - x_min, y_max - y_min))\n",
    "                        \n",
    "                    else:\n",
    "                        current_table.save(os.path.join(page_folder, f\"table_{table_counter}.png\"))\n",
    "                        processed_regions.append((x, y, w, h))\n",
    "                        table_counter += 1\n",
    "                    \n",
    "                    i += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing page {page_num + 1}: {str(e)}\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path, output_dir=\"extracted_tables\", heading_margin=90):\n",
    "    \"\"\"Process the PDF and extract tables.\"\"\"\n",
    "    extractor = PDFTableExtractor(pdf_path, output_dir, heading_margin)\n",
    "    extractor.extract_table_images()\n",
    "    print(f\"Table images saved in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table images saved in: my_tables\n",
      "Extracted images saved in: my_tables\n"
     ]
    }
   ],
   "source": [
    "# from pdf_table_extractor_1_new import process_pdf\n",
    "\n",
    "pdf_path = \"../Pre_Match Report New_removed (1).pdf\"  # Path to your PDF file\n",
    "output_dir = \"my_tables\"  # Directory to store extracted table images\n",
    "heading_margin = 90  # Pixels above tables to include headings\n",
    "\n",
    "# Process the PDF and extract tables\n",
    "extracted_images = process_pdf(pdf_path, output_dir, heading_margin)\n",
    "print(f\"Extracted images saved in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
